{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f3d60",
   "metadata": {},
   "source": [
    "# BPL_TEST2_Batch_calibration - demo\n",
    "\n",
    "This notebook shows the possibilities for calibration of the model BPL_TEST2_Batch using scipy.optimize.minimize() routine. There are several different methods to choose between. In this notebook we work with simulated data.\n",
    "\n",
    "The text-book model of batch cultivation we simulate is the following where $S$ is substrate, $X$ is cell concentration, and $V$ is volume of the broth\n",
    "\n",
    "$$\n",
    "\\eqalign{\n",
    "{d(VS) \\over dt} =& -q_S(S) \\cdot VX \\cr \n",
    "{d(VX) \\over dt} =& \\mu(S) \\cdot VX }\n",
    "$$\n",
    "\n",
    "and where specific cell growth rate $\\mu$ and substrate uptake rate $q_S$ are\n",
    "\n",
    "$$\n",
    "\\mu(S) = Y \\cdot q_S(S)\n",
    "$$\n",
    "\n",
    "$$\n",
    "q_S(S) = q_S^{max} {S \\over K_s + S}\n",
    "$$\n",
    "\n",
    "where $Y$ is the yield, $q_S^{max}$ is the maximal specific substrate uptake rate and $K_s$ is the corresponding saturation constant.\n",
    "\n",
    "The parameter estimation is done with optimization methods that only require evaluation of the missmatch between simulation with given parameters and data. At start the allowed range for each parameter is given. The method used for optimization is Nelder-Mead but can easily be changed [1].\n",
    "\n",
    "In the near future the FMU may provide first derivative gradient informaion, that will make it possible to choose corresponding method of minimize() for improved performance. This possibility is related to the upgrade to the FMI-standard ver 3.0 for the Modelica compiler.  \n",
    "\n",
    "The Python package PyFMI [2] that is the base for FMU-explore has a simplified built-in\n",
    "functionality for parameter estimation that also use scipy.optimize.minimize(). However, there is estimatation functionaly but the purpose seems to only address smaller examples. There is for instance no support to handle models that takes sub-models from libraries and necesssary changes of default parameters not to be estimated. Therefore we here define a Python function evaluate() that facilitate the formulation of the parameter estimation and also bring flexibility to choice of optimization method, default Nelder-Mead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f275fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run -i BPL_TEST2_Batch_fmpy_explore.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the size of diagrams\n",
    "plt.rcParams['figure.figsize'] = [15/2.54, 12/2.54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40649c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_diagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81463e",
   "metadata": {},
   "source": [
    "## 1 Generate data later used for parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generated\n",
    "simulationTime = 6.0\n",
    "par(Y=0.50, qSmax=1.00, Ks=0.1)\n",
    "init(V_start=1.0, VS_start=10, VX_start=1.0)\n",
    "newplot(plotType='Demo_2')\n",
    "#opts['ncp'] = 12\n",
    "simu(simulationTime, options=opts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in a DataFrame for later use\n",
    "data = pd.DataFrame(data={'time':sim_res['time'], 'X':sim_res['bioreactor.c[1]'], 'S':sim_res['bioreactor.c[2]']})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfb9a7",
   "metadata": {},
   "source": [
    "## 2 Simulation with initial guess of parameters compared with data\n",
    "\n",
    "Here we define the parameters that should be estimated and specify allowed ranges. \n",
    "Nominal parameters are chosen as the mid-point of the allowed parameter range. \n",
    "\n",
    "Simulation with these nominal parameter set and compare with data give an idea of who well the model fit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be estimated using parDict names and their bounds\n",
    "parEstim = ['Y', 'qSmax', 'Ks']\n",
    "parBounds = [(0.4, 0.8), (0.7, 1.3), (0.05, 0.20)]\n",
    "parEstim_0 = [np.mean(parBounds[k]) for k in range(len(parBounds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ec8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with nominal parameters\n",
    "newplot(plotType='Demo_1')\n",
    "par(Y=parEstim_0[0], qSmax=parEstim_0[1], Ks=parEstim_0[2])\n",
    "simu(simulationTime)\n",
    "\n",
    "# Show data\n",
    "ax1.plot(data['time'], data['S'],'b*')\n",
    "ax2.plot(data['time'], data['X'],'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation over the parameter ranges given\n",
    "newplot(plotType='Demo_1')\n",
    "for Y_value in parBounds [0]:\n",
    "    for qSmax_value in parBounds[1]:\n",
    "        for Ks_value in parBounds[2]:\n",
    "            par(Y=Y_value, qSmax=qSmax_value, Ks=Ks_value)\n",
    "            simu(simulationTime)\n",
    "            \n",
    "# Show data\n",
    "ax1.plot(data['time'], data['S'],'b*')\n",
    "ax2.plot(data['time'], data['X'],'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87559670",
   "metadata": {},
   "source": [
    "Simulation over the diferent parameter combinations of the parameter bounds shows that data is \"covered\" and we have good hope to find a parameter combination that fits data well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ea5ed",
   "metadata": {},
   "source": [
    "## 3 Parameter estimation\n",
    "\n",
    "Here we use the scipy.optimize.minimize() procedure which contain a family of different methods [1].\n",
    "The default method is Nelder-Mead and is robust for fitting a model to data. Further we have chosen to work with bounds for the parameters to be estimated and the initial guess is chosen as the middle point in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c478aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization routine import\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6384e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be estimated using parDict names and their bounds\n",
    "extra_args = (parEstim, data, fmu_model, simulationTime, parDict, parLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified evaluation function tailored for Python optimization algorithms\n",
    "def objective(x, parEstim, data=data, fmu_model=fmu_model, simulationTime=simulationTime,\n",
    "                parDict=parDict, parLocation=parLocation):\n",
    "    \"\"\"The parameter list is tailored for scipy optimization algorithms interface, \n",
    "       where the first parameter x is an array with parameters that are tuned \n",
    "       and evalauted and parEstim is a list of the names of these parameters.\n",
    "       The code can be made faster, but longer, using fmpy-commands directly.\"\"\"\n",
    "      \n",
    "    # Update parameters and simulate\n",
    "    for i, p in enumerate(parEstim): par(**{p:x[i]}) \n",
    "    simu(simulationTime, options=opts_data)\n",
    "        \n",
    "    # Calculate loss function V\n",
    "    V={}\n",
    "    V['X'] = np.linalg.norm(data['X'] - np.interp(data['time'], sim_res['time'], sim_res['bioreactor.c[1]']))\n",
    "    V['S'] = np.linalg.norm(data['S'] - np.interp(data['time'], sim_res['time'], sim_res['bioreactor.c[2]']))\n",
    "  \n",
    "    return V['X'] + V['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431cdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run minimize()\n",
    "start_time = time.time()\n",
    "result = scipy.optimize.minimize(objective, x0=parEstim_0, args=extra_args, \n",
    "                                 method='Nelder-Mead', bounds=parBounds, options={\"disp\":True})\n",
    "print('CPU-time =', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8116c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69640b",
   "metadata": {},
   "source": [
    "The estimated parameters result.x are very close to the original values and no surprise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fc228",
   "metadata": {},
   "source": [
    "## 4 Simulation with estimated parameters compared with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22729dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "newplot(plotType='Demo_1')\n",
    "par(Y=result.x[0], qSmax=result.x[1], Ks=result.x[2])\n",
    "simu(simulationTime)\n",
    "\n",
    "# Show data\n",
    "ax1.plot(data['time'], data['S'],'b*')\n",
    "ax2.plot(data['time'], data['X'],'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated parameters are\n",
    "for i in range(len(parEstim)): print(parEstim[i],':', result.x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13461de2",
   "metadata": {},
   "source": [
    "## 5 Analysis of the loss function\n",
    "\n",
    "The problem is small and analysis of the loss function brings some insight. From the diagram above showing parameter sweep over combinations min- and max-parameters we see that the parameter $K_s$ has little influence. Let use set that a fixed value and then plot the loss function in the parameters $Y$ and $qSmax$.  We do this by go through all the parametera combinations and evaluate each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep through Y and qSmax variation and store the value of the loss-function for each\n",
    "nY = 20\n",
    "nqSmax = 20\n",
    "V = np.zeros((nY, nqSmax))\n",
    "             \n",
    "Y = np.linspace(parBounds[0][0],parBounds[0][1],nY)\n",
    "qSmax = np.linspace(parBounds[1][0],parBounds[1][1],nqSmax)\n",
    "\n",
    "for j in range(nY):\n",
    "    for k in range(nqSmax):\n",
    "        V[k,j] = objective([Y[j], qSmax[k], 0.1], parEstim)\n",
    "\n",
    "# Contour plot\n",
    "plt.figure()\n",
    "plt.clf\n",
    "plt.subplot(1,1,1)\n",
    "plt.contourf(Y, qSmax, V, 20, cmap='RdGy')\n",
    "plt.plot(result.x[0], result.x[1],'k+')\n",
    "plt.colorbar()\n",
    "plt.ylabel('qSmax')\n",
    "plt.xlabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab08d4",
   "metadata": {},
   "source": [
    "We see the following in the contour diagram of the loss function simplified:\n",
    "* The minima is unique in the range of parmaters we study. This is good news.\n",
    "* The contour plot is ellipsoid and rather narrow. The more narrow the ellipsoid the more difficult and more time it takes to converge to the minima.\n",
    "* The direction of the ellipsoid axis indicate the correlation you may get between the two parameters during the minimization process.\n",
    "\n",
    "Note that the form of the contour plot change with the parameters (and initial values) of the actual proces.\n",
    "You can see the impact by changing the parameters in \"cell # 4\" where data is generated and then just choose to run that cell and the cells below. No need to restart the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fce4c",
   "metadata": {},
   "source": [
    "## 6 Summary\n",
    "\n",
    "A choice was made to work with allowed ranges of parameters to be estimated and a start value was defined as the center point in this parameter space. There are only three methods available in optimize.minimize() that can handle bounds on parameters.\n",
    "\n",
    "An evaluate() function was created that define how the difference beween simulation and data is measured. The function is rather transparent and easy to modify and you may want to change weight on the loss in S and X, for instance. Here they have so far equal weight. \n",
    "\n",
    "The FMU-explore workspace dictionaries partDict[] and parLocation[] are useful also here and simplify the code for the evaluation() function. But we also use the detailed PyFMI-functions to administrate and set parameters of the actual simulation. \n",
    "\n",
    "The call optimize.minimize() has several parameters and can easily be modified, for instance change of method. For fitting a model to data Nelder-Mead is ao a robust and good choice, but can be somewhat slow.\n",
    "\n",
    "The estimated parameters were close to perfect!\n",
    "\n",
    "The contour plot of the simplified loss function shows that the minima is unique and should\n",
    "not be difficult too difficut to obtain. More narrow ellipticaL contour plots would indicate difficulties. Multiple local minima would also be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e69c40",
   "metadata": {},
   "source": [
    "## 7 References\n",
    "\n",
    "[1] Scipy Reference guide on optimize.minimize()\n",
    "[here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html?highlight=minimize)\n",
    "\n",
    "[2] Andersson, C., Åkesson, J., Fuhrer C. : \"PyFMI: A Python package for simulation of coupled dynamic models with the functional mock-up interface\", Centre for Mathematical Sciences, Lund University, Report LUTFNA-5008-2016, 2016. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec5aad",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a884bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe('parts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe('MSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578385e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
